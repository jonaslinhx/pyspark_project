[LOCAL]
spark.app.name = pyspark_project-local
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0
spark.driver.extraJavaOptions = "-Dlog4j.configuration=file:log4j.properties"
spark.master = local[2]
spark.executor.instances = 2
spark.executor.core = 1
spark.executor.memory = 1G
spark.sql.shuffle.partitions = 5

[QA]
spark.app.name = pyspark_project-qa
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0
spark.executor.core = 5
spark.executor.memory = 10G
spark.executor.memoryOverhead = 1G
spark.executor.instances = 20
spark.sql.shuffle.partitions = 800

[PROD]
spark.app.name = pyspark_project
spark.jars.packages = org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0
spark.executor.core = 5
spark.executor.memory = 10G
spark.executor.memoryOverhead = 1G
spark.executor.instances = 20
spark.sql.shuffle.partitions = 800
